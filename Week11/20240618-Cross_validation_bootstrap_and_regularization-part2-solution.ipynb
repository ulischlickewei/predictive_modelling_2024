{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1821d5ab-8d41-4d0d-b05b-d215d1d7830e",
   "metadata": {},
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6c8919-3445-43b8-a26c-f0b16e5eb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import make_scorer\n",
    "from ISLP.models import sklearn_sm\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2c30f4-852b-4370-beb5-71fe23129186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf526b8-36be-4696-8d8e-fb75fcebe589",
   "metadata": {},
   "source": [
    "# Part 1: Case study bootstrap\n",
    "\n",
    "We continue to consider the use of a logistic regression model to predict the probability of default using income and balance on the `Default` data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coefficients in two different ways: \n",
    "1. using the bootstrap, and \n",
    "2. using the standard formula for computing the standard errors in the sm.GLM() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e85f2b4-c0cf-4f3d-9ce9-5cb9a99db209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     default student      balance        income\n",
       "0         No      No   729.526495  44361.625074\n",
       "1         No     Yes   817.180407  12106.134700\n",
       "2         No      No  1073.549164  31767.138947\n",
       "3         No      No   529.250605  35704.493935\n",
       "4         No      No   785.655883  38463.495879\n",
       "...      ...     ...          ...           ...\n",
       "9995      No      No   711.555020  52992.378914\n",
       "9996      No      No   757.962918  19660.721768\n",
       "9997      No      No   845.411989  58636.156984\n",
       "9998      No      No  1569.009053  36669.112365\n",
       "9999      No     Yes   200.922183  16862.952321\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to load the data\n",
    "Default = load_data('Default')\n",
    "Default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee55e0-f562-469e-b8e6-ad15fc52fda5",
   "metadata": {},
   "source": [
    "## Task 1.1\n",
    "Using the `summarize()` and `sm.GLM()` functions, determine the estimated standard errors for the coefficients associated with `income` and `balance` in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece8e8c9-4be6-425f-8191-043b6452645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-11.540500</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>-26.544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.835</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef   std err       z  P>|z|\n",
       "intercept -11.540500  0.435000 -26.544    0.0\n",
       "balance     0.005600  0.000000  24.835    0.0\n",
       "income      0.000021  0.000005   4.174    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = Default.columns.drop(['student', 'default'])\n",
    "design = MS(predictors).fit(Default)\n",
    "X = design.transform(Default)\n",
    "\n",
    "y = Default.default.map({\n",
    "    'No' : 0,\n",
    "    'Yes' : 1\n",
    "})\n",
    "\n",
    "model = sm.Logit(y,X)\n",
    "results = model.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb5ce4-e4bd-4076-989a-96542a570bd8",
   "metadata": {},
   "source": [
    "## Task 1.2\n",
    "Following the bootstrap example in Part 2 above, estimate the standard errors of the logistic regression coefficients for income and balance with the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bfea0f-cced-4ff9-ade9-85790472f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005971566415850255, 2.27073226747463e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Define function to compute one bootstrap sample of the model coefficients\n",
    "def one_bootstrap_model_coefficients():\n",
    "    resample = Default.sample(frac = 1, \n",
    "                           replace = True)\n",
    "    X_bs = design.transform(resample)\n",
    "    y_bs = y[X_bs.index]\n",
    "    results_bs = sm.Logit(y_bs,X_bs).fit(disp=0) # disp=0 option mutes output of fit()\n",
    "    return results_bs.params['balance'], results_bs.params['income']\n",
    "one_bootstrap_model_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b9bb1f-5ea9-4f5a-9388-ad3ffa0a404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: \n",
    "n_bs_samples = 5000\n",
    "balance_coefficients = np.zeros(n_bs_samples)\n",
    "income_coefficients = np.zeros(n_bs_samples)\n",
    "for i in range(n_bs_samples):\n",
    "    balance_coefficients[i], income_coefficients[i] = one_bootstrap_model_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfce934-2864-4497-8f54-b9a70885044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap estimation of standard error for balance parameter:    2.298945e-04\n",
      "Statsmodels estimation of standard error for balance parameter:  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Step 3a: comparison of bootstrap standard errors and standard errors as per statsmodels.Logit() - balance\n",
    "print('Bootstrap estimation of standard error for balance parameter:   ', \n",
    "      '{:6e}'.format(np.std(balance_coefficients))\n",
    ")\n",
    "print('Statsmodels estimation of standard error for balance parameter: ', \n",
    "      '{:6e}'.format(summarize(results).loc['balance','std err'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3456658d-f02f-4318-9831-b33d560f2154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap estimation of standard error for income parameter:    4.854690e-06\n",
      "Statsmodels estimation of standard error for income parameter:  4.990000e-06\n"
     ]
    }
   ],
   "source": [
    "# Step 3b: comparison of bootstrap standard errors and standard errors as per statsmodels.Logit() - income\n",
    "print('Bootstrap estimation of standard error for income parameter:   ', \n",
    "      '{:6e}'.format(np.std(income_coefficients))\n",
    ")\n",
    "print('Statsmodels estimation of standard error for income parameter: ', \n",
    "      '{:6e}'.format(summarize(results).loc['income','std err'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecc781-c801-4abc-b6d7-d3b0da91068c",
   "metadata": {},
   "source": [
    "## Task 1.3\n",
    "\n",
    "Comment on the estimated standard errors obtained using the `sm.Logit()`/`sm.GLM()` function and using the bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d07b5c-8901-4d15-a6fc-57c9cec115d1",
   "metadata": {},
   "source": [
    "**Comment**:\n",
    "- For `balance` the standard error estimated by `statsmodels.Logit()` is 0.0, which is quite different from the bootstrap standard error of 2.26e-04.\n",
    "- For `income` the bootstrap estimate of the standard error is similar to the one estimated by `statsmodels`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155972d-68f4-47db-98bb-2acf8022b963",
   "metadata": {},
   "source": [
    "# Part 2: Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d71fd0-814e-47e3-b567-0f91382d8256",
   "metadata": {},
   "source": [
    "In this section we learn how to implement regularization for linear regression models using Ridge and the Lasso formalisms.\n",
    "\n",
    "We look at a [market research project by a pharmaceutical company](https://www.tandfonline.com/doi/abs/10.1080/02664763.2014.994480) (example taken from the textbook [Learning Data Science](https://learningds.org/ch/16/ms_regularization.html#lipovetsky)) by S. Lau, J. Gonzalez and D. Nolan).\n",
    "\n",
    "The objective of the study is to model consumer interest in purchasing a cold sore health-care product. The study authors gather data from 1,023 consumers. Each consumer is asked to rate on a 10-point scale 35 factors according to whether the factor matters to them when considering purchasing a cold sore treatment. They also rate their interest in purchasing the product.\n",
    "\n",
    "We begin by reading in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f276f6-be7c-4ef8-8f2d-f337eaa86665",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_df = pd.read_csv('market-analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9c753-76b8-4edf-a1af-e75aee76cac1",
   "metadata": {},
   "source": [
    "The table below lists the 35 factors and provides their correlation to the outcome, their interest in purchasing the product:\n",
    "\n",
    "\n",
    "\n",
    "|  | Corr | Description |  | Corr | Description |\n",
    "| --- | --- | --------- | --- | --- | --------- |\n",
    "| x1  | 0.70 | provides soothing relief | x19 | 0.54 | has a non-messy application |\n",
    "| x2  | 0.58 | moisturizes cold sore blister | x20 | 0.70 | good for any stage of a cold |\n",
    "| x3  | 0.69 | provides long-lasting relief | x21 | 0.49 | easy to apply/take |\n",
    "| x4  | 0.70 | provides fast-acting relief | x22 | 0.52 | package keeps from contamination |\n",
    "| x5 | 0.72 | shortens duration of a cold | x23 | 0.57 | easy to dispense a right amount |\n",
    "| x6  | 0.68 | stops the virus from spreading | x24 | 0.63 | worth the price it costs |\n",
    "| x7 | 0.67| dries up cold sore | x25 | 0.57 | recommended most by pharamacists |\n",
    "| x8 | 0.72 | heals fast | x26 | 0.54 | recommended by doctors |\n",
    "| x9 | 0.72 | penetrates deep | x27 | 0.54 | FDA approved |\n",
    "| x10 | 0.65 | relieves pain | x28 | 0.64 | a brand I trust |\n",
    "| x11 |0.61 | prevents cold | x29 | 0.60 | clinically proven |\n",
    "| x12 | 0.73 | prevents from getting worse | x30 | 0.68 | a brand I would recommend |\n",
    "| x13 | 0.57 | medicated | x31 | 0.74 | an effective treatment |\n",
    "| x14 | 0.61 | prescription strength | x32  |0.37 | portable |\n",
    "| x15 | 0.63 | repairs damaged skin | x33 | 0.37 | discreet packaging |\n",
    "| x16 | 0.67 | blocks virus from spreading | x34 | 0.55 | helps conceal cold sores |\n",
    "| x17 | 0.42 | contains SPF | x35 | 0.63 | absorbs quickly |\n",
    "| x18 | 0.57 | non-irritating | | | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f31ccb-4035-4499-90a6-de1246bfb204",
   "metadata": {},
   "source": [
    "Based on their labels alone, some of these 35 features appear to measure similar aspects of desirability. We can compute the correlations between the explanatory variables to confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e87e0e-aef2-4e89-bdc1-2e3425fb6e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.584470</td>\n",
       "      <td>0.689198</td>\n",
       "      <td>0.698104</td>\n",
       "      <td>0.715737</td>\n",
       "      <td>0.675171</td>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.720245</td>\n",
       "      <td>0.715239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543472</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.643565</td>\n",
       "      <td>0.599936</td>\n",
       "      <td>0.681561</td>\n",
       "      <td>0.744036</td>\n",
       "      <td>0.370732</td>\n",
       "      <td>0.365545</td>\n",
       "      <td>0.553436</td>\n",
       "      <td>0.627739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.698082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693949</td>\n",
       "      <td>0.741297</td>\n",
       "      <td>0.806206</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.733237</td>\n",
       "      <td>0.715636</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.781493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545061</td>\n",
       "      <td>0.555448</td>\n",
       "      <td>0.669401</td>\n",
       "      <td>0.632966</td>\n",
       "      <td>0.675034</td>\n",
       "      <td>0.786363</td>\n",
       "      <td>0.420447</td>\n",
       "      <td>0.327813</td>\n",
       "      <td>0.573375</td>\n",
       "      <td>0.714993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.584470</td>\n",
       "      <td>0.693949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632579</td>\n",
       "      <td>0.652231</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>0.626027</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520121</td>\n",
       "      <td>0.535033</td>\n",
       "      <td>0.608308</td>\n",
       "      <td>0.600972</td>\n",
       "      <td>0.618307</td>\n",
       "      <td>0.658305</td>\n",
       "      <td>0.426040</td>\n",
       "      <td>0.355965</td>\n",
       "      <td>0.546330</td>\n",
       "      <td>0.631601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.689198</td>\n",
       "      <td>0.741297</td>\n",
       "      <td>0.632579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775006</td>\n",
       "      <td>0.764568</td>\n",
       "      <td>0.781304</td>\n",
       "      <td>0.716138</td>\n",
       "      <td>0.795831</td>\n",
       "      <td>0.766581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559115</td>\n",
       "      <td>0.571977</td>\n",
       "      <td>0.634122</td>\n",
       "      <td>0.665531</td>\n",
       "      <td>0.635772</td>\n",
       "      <td>0.795528</td>\n",
       "      <td>0.366715</td>\n",
       "      <td>0.343737</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.697526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.698104</td>\n",
       "      <td>0.806206</td>\n",
       "      <td>0.652231</td>\n",
       "      <td>0.775006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791758</td>\n",
       "      <td>0.763113</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.782780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566515</td>\n",
       "      <td>0.550485</td>\n",
       "      <td>0.649257</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.674396</td>\n",
       "      <td>0.816444</td>\n",
       "      <td>0.386155</td>\n",
       "      <td>0.316505</td>\n",
       "      <td>0.595784</td>\n",
       "      <td>0.715873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.715737</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>0.764568</td>\n",
       "      <td>0.791758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784662</td>\n",
       "      <td>0.728638</td>\n",
       "      <td>0.848203</td>\n",
       "      <td>0.767637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585059</td>\n",
       "      <td>0.541089</td>\n",
       "      <td>0.634308</td>\n",
       "      <td>0.631482</td>\n",
       "      <td>0.683331</td>\n",
       "      <td>0.820550</td>\n",
       "      <td>0.341707</td>\n",
       "      <td>0.315925</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>0.692399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>0.675171</td>\n",
       "      <td>0.733237</td>\n",
       "      <td>0.626027</td>\n",
       "      <td>0.781304</td>\n",
       "      <td>0.763113</td>\n",
       "      <td>0.784662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723374</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.776645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601352</td>\n",
       "      <td>0.610401</td>\n",
       "      <td>0.619591</td>\n",
       "      <td>0.692060</td>\n",
       "      <td>0.657196</td>\n",
       "      <td>0.781734</td>\n",
       "      <td>0.342936</td>\n",
       "      <td>0.366826</td>\n",
       "      <td>0.644575</td>\n",
       "      <td>0.683923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.715636</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.716138</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>0.728638</td>\n",
       "      <td>0.723374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735611</td>\n",
       "      <td>0.762535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572395</td>\n",
       "      <td>0.576887</td>\n",
       "      <td>0.665014</td>\n",
       "      <td>0.677444</td>\n",
       "      <td>0.645748</td>\n",
       "      <td>0.751695</td>\n",
       "      <td>0.367301</td>\n",
       "      <td>0.389850</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>0.707176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>0.720245</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.795831</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.848203</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.735611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562062</td>\n",
       "      <td>0.535833</td>\n",
       "      <td>0.631658</td>\n",
       "      <td>0.645374</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.837631</td>\n",
       "      <td>0.320365</td>\n",
       "      <td>0.315380</td>\n",
       "      <td>0.623694</td>\n",
       "      <td>0.689579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <td>0.715239</td>\n",
       "      <td>0.781493</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>0.766581</td>\n",
       "      <td>0.782780</td>\n",
       "      <td>0.767637</td>\n",
       "      <td>0.776645</td>\n",
       "      <td>0.762535</td>\n",
       "      <td>0.780745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>0.603364</td>\n",
       "      <td>0.681121</td>\n",
       "      <td>0.699057</td>\n",
       "      <td>0.711266</td>\n",
       "      <td>0.815086</td>\n",
       "      <td>0.420671</td>\n",
       "      <td>0.354331</td>\n",
       "      <td>0.608952</td>\n",
       "      <td>0.743931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x10</th>\n",
       "      <td>0.649949</td>\n",
       "      <td>0.776816</td>\n",
       "      <td>0.639618</td>\n",
       "      <td>0.771075</td>\n",
       "      <td>0.771555</td>\n",
       "      <td>0.732540</td>\n",
       "      <td>0.712169</td>\n",
       "      <td>0.692195</td>\n",
       "      <td>0.756710</td>\n",
       "      <td>0.721806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555538</td>\n",
       "      <td>0.549870</td>\n",
       "      <td>0.613499</td>\n",
       "      <td>0.610839</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.749348</td>\n",
       "      <td>0.411146</td>\n",
       "      <td>0.354864</td>\n",
       "      <td>0.588309</td>\n",
       "      <td>0.709310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x11</th>\n",
       "      <td>0.611217</td>\n",
       "      <td>0.611083</td>\n",
       "      <td>0.527309</td>\n",
       "      <td>0.729685</td>\n",
       "      <td>0.673712</td>\n",
       "      <td>0.682437</td>\n",
       "      <td>0.725510</td>\n",
       "      <td>0.626559</td>\n",
       "      <td>0.711009</td>\n",
       "      <td>0.666614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560835</td>\n",
       "      <td>0.527375</td>\n",
       "      <td>0.496170</td>\n",
       "      <td>0.599517</td>\n",
       "      <td>0.545051</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.202876</td>\n",
       "      <td>0.324905</td>\n",
       "      <td>0.718138</td>\n",
       "      <td>0.597996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x12</th>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.754876</td>\n",
       "      <td>0.670570</td>\n",
       "      <td>0.781752</td>\n",
       "      <td>0.780375</td>\n",
       "      <td>0.823553</td>\n",
       "      <td>0.799534</td>\n",
       "      <td>0.734402</td>\n",
       "      <td>0.819808</td>\n",
       "      <td>0.790453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589416</td>\n",
       "      <td>0.581239</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.674152</td>\n",
       "      <td>0.694640</td>\n",
       "      <td>0.831677</td>\n",
       "      <td>0.359118</td>\n",
       "      <td>0.333246</td>\n",
       "      <td>0.614646</td>\n",
       "      <td>0.690204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x13</th>\n",
       "      <td>0.568543</td>\n",
       "      <td>0.642607</td>\n",
       "      <td>0.581479</td>\n",
       "      <td>0.554083</td>\n",
       "      <td>0.615811</td>\n",
       "      <td>0.557886</td>\n",
       "      <td>0.558224</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.547323</td>\n",
       "      <td>0.611135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520003</td>\n",
       "      <td>0.553617</td>\n",
       "      <td>0.643270</td>\n",
       "      <td>0.589885</td>\n",
       "      <td>0.625929</td>\n",
       "      <td>0.618988</td>\n",
       "      <td>0.502908</td>\n",
       "      <td>0.381618</td>\n",
       "      <td>0.380178</td>\n",
       "      <td>0.619825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x14</th>\n",
       "      <td>0.612810</td>\n",
       "      <td>0.621350</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.673819</td>\n",
       "      <td>0.655797</td>\n",
       "      <td>0.652915</td>\n",
       "      <td>0.699822</td>\n",
       "      <td>0.658530</td>\n",
       "      <td>0.686095</td>\n",
       "      <td>0.691409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665078</td>\n",
       "      <td>0.636700</td>\n",
       "      <td>0.538207</td>\n",
       "      <td>0.690002</td>\n",
       "      <td>0.603546</td>\n",
       "      <td>0.688899</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>0.381576</td>\n",
       "      <td>0.625440</td>\n",
       "      <td>0.633840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x15</th>\n",
       "      <td>0.633805</td>\n",
       "      <td>0.652888</td>\n",
       "      <td>0.637129</td>\n",
       "      <td>0.703301</td>\n",
       "      <td>0.664885</td>\n",
       "      <td>0.657942</td>\n",
       "      <td>0.670779</td>\n",
       "      <td>0.642211</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.661460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561494</td>\n",
       "      <td>0.580042</td>\n",
       "      <td>0.538412</td>\n",
       "      <td>0.627879</td>\n",
       "      <td>0.571214</td>\n",
       "      <td>0.644948</td>\n",
       "      <td>0.349019</td>\n",
       "      <td>0.375328</td>\n",
       "      <td>0.676788</td>\n",
       "      <td>0.636210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x16</th>\n",
       "      <td>0.672733</td>\n",
       "      <td>0.704688</td>\n",
       "      <td>0.653608</td>\n",
       "      <td>0.767164</td>\n",
       "      <td>0.760082</td>\n",
       "      <td>0.770461</td>\n",
       "      <td>0.846043</td>\n",
       "      <td>0.720935</td>\n",
       "      <td>0.783645</td>\n",
       "      <td>0.760231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612095</td>\n",
       "      <td>0.611128</td>\n",
       "      <td>0.625385</td>\n",
       "      <td>0.690917</td>\n",
       "      <td>0.659901</td>\n",
       "      <td>0.787172</td>\n",
       "      <td>0.353463</td>\n",
       "      <td>0.372951</td>\n",
       "      <td>0.655194</td>\n",
       "      <td>0.694094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x17</th>\n",
       "      <td>0.422587</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>0.506058</td>\n",
       "      <td>0.462482</td>\n",
       "      <td>0.442422</td>\n",
       "      <td>0.427191</td>\n",
       "      <td>0.467452</td>\n",
       "      <td>0.447118</td>\n",
       "      <td>0.440363</td>\n",
       "      <td>0.444145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542576</td>\n",
       "      <td>0.549343</td>\n",
       "      <td>0.425320</td>\n",
       "      <td>0.505704</td>\n",
       "      <td>0.447273</td>\n",
       "      <td>0.439266</td>\n",
       "      <td>0.300796</td>\n",
       "      <td>0.447006</td>\n",
       "      <td>0.512122</td>\n",
       "      <td>0.435224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x18</th>\n",
       "      <td>0.569995</td>\n",
       "      <td>0.661484</td>\n",
       "      <td>0.607966</td>\n",
       "      <td>0.609121</td>\n",
       "      <td>0.625844</td>\n",
       "      <td>0.598892</td>\n",
       "      <td>0.575875</td>\n",
       "      <td>0.592607</td>\n",
       "      <td>0.574531</td>\n",
       "      <td>0.636093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474494</td>\n",
       "      <td>0.537704</td>\n",
       "      <td>0.619053</td>\n",
       "      <td>0.563715</td>\n",
       "      <td>0.604082</td>\n",
       "      <td>0.656679</td>\n",
       "      <td>0.522483</td>\n",
       "      <td>0.319780</td>\n",
       "      <td>0.388265</td>\n",
       "      <td>0.650405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x19</th>\n",
       "      <td>0.542272</td>\n",
       "      <td>0.607750</td>\n",
       "      <td>0.531957</td>\n",
       "      <td>0.572787</td>\n",
       "      <td>0.561500</td>\n",
       "      <td>0.545316</td>\n",
       "      <td>0.554359</td>\n",
       "      <td>0.540151</td>\n",
       "      <td>0.526068</td>\n",
       "      <td>0.596012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497970</td>\n",
       "      <td>0.486676</td>\n",
       "      <td>0.564426</td>\n",
       "      <td>0.554017</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.547819</td>\n",
       "      <td>0.462715</td>\n",
       "      <td>0.373376</td>\n",
       "      <td>0.484641</td>\n",
       "      <td>0.655057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x20</th>\n",
       "      <td>0.700657</td>\n",
       "      <td>0.747502</td>\n",
       "      <td>0.643024</td>\n",
       "      <td>0.767980</td>\n",
       "      <td>0.755620</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>0.751129</td>\n",
       "      <td>0.744164</td>\n",
       "      <td>0.789432</td>\n",
       "      <td>0.795093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565536</td>\n",
       "      <td>0.589483</td>\n",
       "      <td>0.709596</td>\n",
       "      <td>0.671242</td>\n",
       "      <td>0.700305</td>\n",
       "      <td>0.819639</td>\n",
       "      <td>0.406118</td>\n",
       "      <td>0.366284</td>\n",
       "      <td>0.560601</td>\n",
       "      <td>0.711878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x21</th>\n",
       "      <td>0.485877</td>\n",
       "      <td>0.593437</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.461305</td>\n",
       "      <td>0.559467</td>\n",
       "      <td>0.510594</td>\n",
       "      <td>0.484669</td>\n",
       "      <td>0.525381</td>\n",
       "      <td>0.480301</td>\n",
       "      <td>0.582163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414621</td>\n",
       "      <td>0.390935</td>\n",
       "      <td>0.597191</td>\n",
       "      <td>0.491745</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.554530</td>\n",
       "      <td>0.575930</td>\n",
       "      <td>0.303190</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.566070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x22</th>\n",
       "      <td>0.524744</td>\n",
       "      <td>0.564605</td>\n",
       "      <td>0.536935</td>\n",
       "      <td>0.542698</td>\n",
       "      <td>0.537610</td>\n",
       "      <td>0.524055</td>\n",
       "      <td>0.564114</td>\n",
       "      <td>0.563105</td>\n",
       "      <td>0.557442</td>\n",
       "      <td>0.563278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526011</td>\n",
       "      <td>0.529342</td>\n",
       "      <td>0.573263</td>\n",
       "      <td>0.579489</td>\n",
       "      <td>0.564812</td>\n",
       "      <td>0.557209</td>\n",
       "      <td>0.396537</td>\n",
       "      <td>0.471032</td>\n",
       "      <td>0.484318</td>\n",
       "      <td>0.557158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x23</th>\n",
       "      <td>0.570167</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>0.615791</td>\n",
       "      <td>0.577429</td>\n",
       "      <td>0.624812</td>\n",
       "      <td>0.563219</td>\n",
       "      <td>0.577213</td>\n",
       "      <td>0.610632</td>\n",
       "      <td>0.564193</td>\n",
       "      <td>0.650347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479461</td>\n",
       "      <td>0.500161</td>\n",
       "      <td>0.623812</td>\n",
       "      <td>0.547664</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.636781</td>\n",
       "      <td>0.475590</td>\n",
       "      <td>0.399486</td>\n",
       "      <td>0.428344</td>\n",
       "      <td>0.619043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x24</th>\n",
       "      <td>0.626001</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.602444</td>\n",
       "      <td>0.689196</td>\n",
       "      <td>0.690506</td>\n",
       "      <td>0.706235</td>\n",
       "      <td>0.671581</td>\n",
       "      <td>0.666485</td>\n",
       "      <td>0.697303</td>\n",
       "      <td>0.720666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540872</td>\n",
       "      <td>0.538632</td>\n",
       "      <td>0.654973</td>\n",
       "      <td>0.623942</td>\n",
       "      <td>0.659731</td>\n",
       "      <td>0.732138</td>\n",
       "      <td>0.376494</td>\n",
       "      <td>0.310129</td>\n",
       "      <td>0.535798</td>\n",
       "      <td>0.659040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x25</th>\n",
       "      <td>0.565332</td>\n",
       "      <td>0.562947</td>\n",
       "      <td>0.504240</td>\n",
       "      <td>0.563532</td>\n",
       "      <td>0.579929</td>\n",
       "      <td>0.571659</td>\n",
       "      <td>0.594267</td>\n",
       "      <td>0.583720</td>\n",
       "      <td>0.558173</td>\n",
       "      <td>0.601029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717083</td>\n",
       "      <td>0.642689</td>\n",
       "      <td>0.535851</td>\n",
       "      <td>0.694629</td>\n",
       "      <td>0.607991</td>\n",
       "      <td>0.574407</td>\n",
       "      <td>0.333278</td>\n",
       "      <td>0.405347</td>\n",
       "      <td>0.546764</td>\n",
       "      <td>0.568196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x26</th>\n",
       "      <td>0.543472</td>\n",
       "      <td>0.545061</td>\n",
       "      <td>0.520121</td>\n",
       "      <td>0.559115</td>\n",
       "      <td>0.566515</td>\n",
       "      <td>0.585059</td>\n",
       "      <td>0.601352</td>\n",
       "      <td>0.572395</td>\n",
       "      <td>0.562062</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727449</td>\n",
       "      <td>0.535094</td>\n",
       "      <td>0.674711</td>\n",
       "      <td>0.593661</td>\n",
       "      <td>0.570371</td>\n",
       "      <td>0.312459</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.519789</td>\n",
       "      <td>0.578550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x27</th>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.555448</td>\n",
       "      <td>0.535033</td>\n",
       "      <td>0.571977</td>\n",
       "      <td>0.550485</td>\n",
       "      <td>0.541089</td>\n",
       "      <td>0.610401</td>\n",
       "      <td>0.576887</td>\n",
       "      <td>0.535833</td>\n",
       "      <td>0.603364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571533</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.592333</td>\n",
       "      <td>0.574348</td>\n",
       "      <td>0.379691</td>\n",
       "      <td>0.425666</td>\n",
       "      <td>0.483709</td>\n",
       "      <td>0.580368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x28</th>\n",
       "      <td>0.643565</td>\n",
       "      <td>0.669401</td>\n",
       "      <td>0.608308</td>\n",
       "      <td>0.634122</td>\n",
       "      <td>0.649257</td>\n",
       "      <td>0.634308</td>\n",
       "      <td>0.619591</td>\n",
       "      <td>0.665014</td>\n",
       "      <td>0.631658</td>\n",
       "      <td>0.681121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535094</td>\n",
       "      <td>0.571533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607119</td>\n",
       "      <td>0.726389</td>\n",
       "      <td>0.697303</td>\n",
       "      <td>0.472343</td>\n",
       "      <td>0.400223</td>\n",
       "      <td>0.437641</td>\n",
       "      <td>0.663913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x29</th>\n",
       "      <td>0.599936</td>\n",
       "      <td>0.632966</td>\n",
       "      <td>0.600972</td>\n",
       "      <td>0.665531</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.631482</td>\n",
       "      <td>0.692060</td>\n",
       "      <td>0.677444</td>\n",
       "      <td>0.645374</td>\n",
       "      <td>0.699057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674711</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.607119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616650</td>\n",
       "      <td>0.677428</td>\n",
       "      <td>0.437348</td>\n",
       "      <td>0.385824</td>\n",
       "      <td>0.582026</td>\n",
       "      <td>0.653886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x30</th>\n",
       "      <td>0.681561</td>\n",
       "      <td>0.675034</td>\n",
       "      <td>0.618307</td>\n",
       "      <td>0.635772</td>\n",
       "      <td>0.674396</td>\n",
       "      <td>0.683331</td>\n",
       "      <td>0.657196</td>\n",
       "      <td>0.645748</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.711266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593661</td>\n",
       "      <td>0.592333</td>\n",
       "      <td>0.726389</td>\n",
       "      <td>0.616650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.699659</td>\n",
       "      <td>0.454541</td>\n",
       "      <td>0.412654</td>\n",
       "      <td>0.478641</td>\n",
       "      <td>0.672371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x31</th>\n",
       "      <td>0.744036</td>\n",
       "      <td>0.786363</td>\n",
       "      <td>0.658305</td>\n",
       "      <td>0.795528</td>\n",
       "      <td>0.816444</td>\n",
       "      <td>0.820550</td>\n",
       "      <td>0.781734</td>\n",
       "      <td>0.751695</td>\n",
       "      <td>0.837631</td>\n",
       "      <td>0.815086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570371</td>\n",
       "      <td>0.574348</td>\n",
       "      <td>0.697303</td>\n",
       "      <td>0.677428</td>\n",
       "      <td>0.699659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404366</td>\n",
       "      <td>0.349842</td>\n",
       "      <td>0.581760</td>\n",
       "      <td>0.722193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x32</th>\n",
       "      <td>0.370732</td>\n",
       "      <td>0.420447</td>\n",
       "      <td>0.426040</td>\n",
       "      <td>0.366715</td>\n",
       "      <td>0.386155</td>\n",
       "      <td>0.341707</td>\n",
       "      <td>0.342936</td>\n",
       "      <td>0.367301</td>\n",
       "      <td>0.320365</td>\n",
       "      <td>0.420671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312459</td>\n",
       "      <td>0.379691</td>\n",
       "      <td>0.472343</td>\n",
       "      <td>0.437348</td>\n",
       "      <td>0.454541</td>\n",
       "      <td>0.404366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338478</td>\n",
       "      <td>0.155003</td>\n",
       "      <td>0.461552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x33</th>\n",
       "      <td>0.365545</td>\n",
       "      <td>0.327813</td>\n",
       "      <td>0.355965</td>\n",
       "      <td>0.343737</td>\n",
       "      <td>0.316505</td>\n",
       "      <td>0.315925</td>\n",
       "      <td>0.366826</td>\n",
       "      <td>0.389850</td>\n",
       "      <td>0.315380</td>\n",
       "      <td>0.354331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.425666</td>\n",
       "      <td>0.400223</td>\n",
       "      <td>0.385824</td>\n",
       "      <td>0.412654</td>\n",
       "      <td>0.349842</td>\n",
       "      <td>0.338478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345458</td>\n",
       "      <td>0.358755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x34</th>\n",
       "      <td>0.553436</td>\n",
       "      <td>0.573375</td>\n",
       "      <td>0.546330</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.595784</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>0.644575</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>0.623694</td>\n",
       "      <td>0.608952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519789</td>\n",
       "      <td>0.483709</td>\n",
       "      <td>0.437641</td>\n",
       "      <td>0.582026</td>\n",
       "      <td>0.478641</td>\n",
       "      <td>0.581760</td>\n",
       "      <td>0.155003</td>\n",
       "      <td>0.345458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x35</th>\n",
       "      <td>0.627739</td>\n",
       "      <td>0.714993</td>\n",
       "      <td>0.631601</td>\n",
       "      <td>0.697526</td>\n",
       "      <td>0.715873</td>\n",
       "      <td>0.692399</td>\n",
       "      <td>0.683923</td>\n",
       "      <td>0.707176</td>\n",
       "      <td>0.689579</td>\n",
       "      <td>0.743931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578550</td>\n",
       "      <td>0.580368</td>\n",
       "      <td>0.663913</td>\n",
       "      <td>0.653886</td>\n",
       "      <td>0.672371</td>\n",
       "      <td>0.722193</td>\n",
       "      <td>0.461552</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.538395</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        x1        x2        x3        x4        x5        x6  \\\n",
       "y    1.000000  0.698082  0.584470  0.689198  0.698104  0.715737  0.675171   \n",
       "x1   0.698082  1.000000  0.693949  0.741297  0.806206  0.745964  0.733237   \n",
       "x2   0.584470  0.693949  1.000000  0.632579  0.652231  0.629310  0.626027   \n",
       "x3   0.689198  0.741297  0.632579  1.000000  0.775006  0.764568  0.781304   \n",
       "x4   0.698104  0.806206  0.652231  0.775006  1.000000  0.791758  0.763113   \n",
       "x5   0.715737  0.745964  0.629310  0.764568  0.791758  1.000000  0.784662   \n",
       "x6   0.675171  0.733237  0.626027  0.781304  0.763113  0.784662  1.000000   \n",
       "x7   0.674324  0.715636  0.606470  0.716138  0.742654  0.728638  0.723374   \n",
       "x8   0.720245  0.764331  0.628247  0.795831  0.812947  0.848203  0.787879   \n",
       "x9   0.715239  0.781493  0.667748  0.766581  0.782780  0.767637  0.776645   \n",
       "x10  0.649949  0.776816  0.639618  0.771075  0.771555  0.732540  0.712169   \n",
       "x11  0.611217  0.611083  0.527309  0.729685  0.673712  0.682437  0.725510   \n",
       "x12  0.734366  0.754876  0.670570  0.781752  0.780375  0.823553  0.799534   \n",
       "x13  0.568543  0.642607  0.581479  0.554083  0.615811  0.557886  0.558224   \n",
       "x14  0.612810  0.621350  0.568400  0.673819  0.655797  0.652915  0.699822   \n",
       "x15  0.633805  0.652888  0.637129  0.703301  0.664885  0.657942  0.670779   \n",
       "x16  0.672733  0.704688  0.653608  0.767164  0.760082  0.770461  0.846043   \n",
       "x17  0.422587  0.419222  0.506058  0.462482  0.442422  0.427191  0.467452   \n",
       "x18  0.569995  0.661484  0.607966  0.609121  0.625844  0.598892  0.575875   \n",
       "x19  0.542272  0.607750  0.531957  0.572787  0.561500  0.545316  0.554359   \n",
       "x20  0.700657  0.747502  0.643024  0.767980  0.755620  0.778752  0.751129   \n",
       "x21  0.485877  0.593437  0.556616  0.461305  0.559467  0.510594  0.484669   \n",
       "x22  0.524744  0.564605  0.536935  0.542698  0.537610  0.524055  0.564114   \n",
       "x23  0.570167  0.647000  0.615791  0.577429  0.624812  0.563219  0.577213   \n",
       "x24  0.626001  0.652671  0.602444  0.689196  0.690506  0.706235  0.671581   \n",
       "x25  0.565332  0.562947  0.504240  0.563532  0.579929  0.571659  0.594267   \n",
       "x26  0.543472  0.545061  0.520121  0.559115  0.566515  0.585059  0.601352   \n",
       "x27  0.535300  0.555448  0.535033  0.571977  0.550485  0.541089  0.610401   \n",
       "x28  0.643565  0.669401  0.608308  0.634122  0.649257  0.634308  0.619591   \n",
       "x29  0.599936  0.632966  0.600972  0.665531  0.628049  0.631482  0.692060   \n",
       "x30  0.681561  0.675034  0.618307  0.635772  0.674396  0.683331  0.657196   \n",
       "x31  0.744036  0.786363  0.658305  0.795528  0.816444  0.820550  0.781734   \n",
       "x32  0.370732  0.420447  0.426040  0.366715  0.386155  0.341707  0.342936   \n",
       "x33  0.365545  0.327813  0.355965  0.343737  0.316505  0.315925  0.366826   \n",
       "x34  0.553436  0.573375  0.546330  0.667460  0.595784  0.587228  0.644575   \n",
       "x35  0.627739  0.714993  0.631601  0.697526  0.715873  0.692399  0.683923   \n",
       "\n",
       "           x7        x8        x9  ...       x26       x27       x28  \\\n",
       "y    0.674324  0.720245  0.715239  ...  0.543472  0.535300  0.643565   \n",
       "x1   0.715636  0.764331  0.781493  ...  0.545061  0.555448  0.669401   \n",
       "x2   0.606470  0.628247  0.667748  ...  0.520121  0.535033  0.608308   \n",
       "x3   0.716138  0.795831  0.766581  ...  0.559115  0.571977  0.634122   \n",
       "x4   0.742654  0.812947  0.782780  ...  0.566515  0.550485  0.649257   \n",
       "x5   0.728638  0.848203  0.767637  ...  0.585059  0.541089  0.634308   \n",
       "x6   0.723374  0.787879  0.776645  ...  0.601352  0.610401  0.619591   \n",
       "x7   1.000000  0.735611  0.762535  ...  0.572395  0.576887  0.665014   \n",
       "x8   0.735611  1.000000  0.780745  ...  0.562062  0.535833  0.631658   \n",
       "x9   0.762535  0.780745  1.000000  ...  0.592798  0.603364  0.681121   \n",
       "x10  0.692195  0.756710  0.721806  ...  0.555538  0.549870  0.613499   \n",
       "x11  0.626559  0.711009  0.666614  ...  0.560835  0.527375  0.496170   \n",
       "x12  0.734402  0.819808  0.790453  ...  0.589416  0.581239  0.656693   \n",
       "x13  0.606300  0.547323  0.611135  ...  0.520003  0.553617  0.643270   \n",
       "x14  0.658530  0.686095  0.691409  ...  0.665078  0.636700  0.538207   \n",
       "x15  0.642211  0.689291  0.661460  ...  0.561494  0.580042  0.538412   \n",
       "x16  0.720935  0.783645  0.760231  ...  0.612095  0.611128  0.625385   \n",
       "x17  0.447118  0.440363  0.444145  ...  0.542576  0.549343  0.425320   \n",
       "x18  0.592607  0.574531  0.636093  ...  0.474494  0.537704  0.619053   \n",
       "x19  0.540151  0.526068  0.596012  ...  0.497970  0.486676  0.564426   \n",
       "x20  0.744164  0.789432  0.795093  ...  0.565536  0.589483  0.709596   \n",
       "x21  0.525381  0.480301  0.582163  ...  0.414621  0.390935  0.597191   \n",
       "x22  0.563105  0.557442  0.563278  ...  0.526011  0.529342  0.573263   \n",
       "x23  0.610632  0.564193  0.650347  ...  0.479461  0.500161  0.623812   \n",
       "x24  0.666485  0.697303  0.720666  ...  0.540872  0.538632  0.654973   \n",
       "x25  0.583720  0.558173  0.601029  ...  0.717083  0.642689  0.535851   \n",
       "x26  0.572395  0.562062  0.592798  ...  1.000000  0.727449  0.535094   \n",
       "x27  0.576887  0.535833  0.603364  ...  0.727449  1.000000  0.571533   \n",
       "x28  0.665014  0.631658  0.681121  ...  0.535094  0.571533  1.000000   \n",
       "x29  0.677444  0.645374  0.699057  ...  0.674711  0.690558  0.607119   \n",
       "x30  0.645748  0.656173  0.711266  ...  0.593661  0.592333  0.726389   \n",
       "x31  0.751695  0.837631  0.815086  ...  0.570371  0.574348  0.697303   \n",
       "x32  0.367301  0.320365  0.420671  ...  0.312459  0.379691  0.472343   \n",
       "x33  0.389850  0.315380  0.354331  ...  0.404087  0.425666  0.400223   \n",
       "x34  0.581250  0.623694  0.608952  ...  0.519789  0.483709  0.437641   \n",
       "x35  0.707176  0.689579  0.743931  ...  0.578550  0.580368  0.663913   \n",
       "\n",
       "          x29       x30       x31       x32       x33       x34       x35  \n",
       "y    0.599936  0.681561  0.744036  0.370732  0.365545  0.553436  0.627739  \n",
       "x1   0.632966  0.675034  0.786363  0.420447  0.327813  0.573375  0.714993  \n",
       "x2   0.600972  0.618307  0.658305  0.426040  0.355965  0.546330  0.631601  \n",
       "x3   0.665531  0.635772  0.795528  0.366715  0.343737  0.667460  0.697526  \n",
       "x4   0.628049  0.674396  0.816444  0.386155  0.316505  0.595784  0.715873  \n",
       "x5   0.631482  0.683331  0.820550  0.341707  0.315925  0.587228  0.692399  \n",
       "x6   0.692060  0.657196  0.781734  0.342936  0.366826  0.644575  0.683923  \n",
       "x7   0.677444  0.645748  0.751695  0.367301  0.389850  0.581250  0.707176  \n",
       "x8   0.645374  0.656173  0.837631  0.320365  0.315380  0.623694  0.689579  \n",
       "x9   0.699057  0.711266  0.815086  0.420671  0.354331  0.608952  0.743931  \n",
       "x10  0.610839  0.636189  0.749348  0.411146  0.354864  0.588309  0.709310  \n",
       "x11  0.599517  0.545051  0.678749  0.202876  0.324905  0.718138  0.597996  \n",
       "x12  0.674152  0.694640  0.831677  0.359118  0.333246  0.614646  0.690204  \n",
       "x13  0.589885  0.625929  0.618988  0.502908  0.381618  0.380178  0.619825  \n",
       "x14  0.690002  0.603546  0.688899  0.324360  0.381576  0.625440  0.633840  \n",
       "x15  0.627879  0.571214  0.644948  0.349019  0.375328  0.676788  0.636210  \n",
       "x16  0.690917  0.659901  0.787172  0.353463  0.372951  0.655194  0.694094  \n",
       "x17  0.505704  0.447273  0.439266  0.300796  0.447006  0.512122  0.435224  \n",
       "x18  0.563715  0.604082  0.656679  0.522483  0.319780  0.388265  0.650405  \n",
       "x19  0.554017  0.541284  0.547819  0.462715  0.373376  0.484641  0.655057  \n",
       "x20  0.671242  0.700305  0.819639  0.406118  0.366284  0.560601  0.711878  \n",
       "x21  0.491745  0.549600  0.554530  0.575930  0.303190  0.325128  0.566070  \n",
       "x22  0.579489  0.564812  0.557209  0.396537  0.471032  0.484318  0.557158  \n",
       "x23  0.547664  0.597342  0.636781  0.475590  0.399486  0.428344  0.619043  \n",
       "x24  0.623942  0.659731  0.732138  0.376494  0.310129  0.535798  0.659040  \n",
       "x25  0.694629  0.607991  0.574407  0.333278  0.405347  0.546764  0.568196  \n",
       "x26  0.674711  0.593661  0.570371  0.312459  0.404087  0.519789  0.578550  \n",
       "x27  0.690558  0.592333  0.574348  0.379691  0.425666  0.483709  0.580368  \n",
       "x28  0.607119  0.726389  0.697303  0.472343  0.400223  0.437641  0.663913  \n",
       "x29  1.000000  0.616650  0.677428  0.437348  0.385824  0.582026  0.653886  \n",
       "x30  0.616650  1.000000  0.699659  0.454541  0.412654  0.478641  0.672371  \n",
       "x31  0.677428  0.699659  1.000000  0.404366  0.349842  0.581760  0.722193  \n",
       "x32  0.437348  0.454541  0.404366  1.000000  0.338478  0.155003  0.461552  \n",
       "x33  0.385824  0.412654  0.349842  0.338478  1.000000  0.345458  0.358755  \n",
       "x34  0.582026  0.478641  0.581760  0.155003  0.345458  1.000000  0.538395  \n",
       "x35  0.653886  0.672371  0.722193  0.461552  0.358755  0.538395  1.000000  \n",
       "\n",
       "[36 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca6b7e-7800-4289-830c-dd2ade47b3b9",
   "metadata": {},
   "source": [
    "We observe for example that the last feature `x35` (\"arsorbs quickly\") is highly correlated to `x1` (\"provides soothing relief\"), `x4` (\"provides fast-acting relief\") or `x9` (\"penetrates deep\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e2474-8d6a-4459-b576-dcdf4e2cd5bb",
   "metadata": {},
   "source": [
    "## Task 2.1\n",
    "\n",
    "Split the data into train and test sets. Use a test set size of 200 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667898d-c6c9-40de-9570-12f9da7d8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ma_df[\"y\"]\n",
    "X = ma_df.drop(columns=[\"y\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c3df3-57f4-4746-8a7a-4070b54322e8",
   "metadata": {},
   "source": [
    "## Task 2.2\n",
    "\n",
    "Standardize the features using the `sklearn.preprocessing.StandardScaler()` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) method. Note that only the predictors need to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f82af-2eda-457c-86ef-d17ac2016950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_scaled = ...\n",
    "X_test_scaled = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71842a82-c7f4-49be-bb60-cc12f078a20c",
   "metadata": {},
   "source": [
    "Run the cell below to check that scaled training data has mean 0 and SD 1 (approximately):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9b022-0ac7-4c31-8f06-ae5c4a529666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acc72a-1bde-4272-9ea7-945ef5fa9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92088dd1-263c-482d-99d8-89293c633e2b",
   "metadata": {},
   "source": [
    "Note that this is **not** the case for the test data (**why?**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aca358-b1ec-44a6-9dc6-a2d9a02666bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f45bd-d02f-4832-af1d-2ed5b9a901f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4930fc5-b1a8-46ee-b8d2-7335c3b0bf9d",
   "metadata": {},
   "source": [
    "## Task 2.3\n",
    "\n",
    "We start by computing an ordinary multiple linear regression model. For consistency with the subsequent tasks we use `sklearn.linear_models.LinearRegression` this time (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "In the following, train a Multiple Linear Regression model on the scaled training data.\n",
    "\n",
    "Compute the model coefficients (using the `coef_` attribute of the trained model) and the mean squared error on the test data (using the function `sklearn.metrics.mean_squared_error()` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html))).\n",
    "\n",
    "*Note*: The design matrix and the results vector are passed only as arguments to the `fit()` method for `sklearn` models. This is different than for `statsmodels` where we passed the data already at the stage of initializing the model. Additionally, the order in which the design matrix and the results vector are passed to a `sklearn`-model is swapped compared to `statsmodels`!\n",
    "\n",
    "Also note: for linear models in `sklearn` we do not need to manually create an `intercept` column as we can specify if we want an intercept to be included using the `fit_intercept` argument when initializing the model. This parameter is set to `True` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41e0c3-bea2-4de4-b681-2d4e7ce7e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "coefficients = ...\n",
    "mse = ...\n",
    "\n",
    "print('Multiple Linear Regression model coefficients: ', coefficients)\n",
    "print('Mutiple Linear Regression test MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a86ed7-152a-409d-b9b8-8f97f4f7ccea",
   "metadata": {},
   "source": [
    "## Task 2.4\n",
    "\n",
    "Repeat Task 4.3, but this time train your model on the unscaled data. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c4e63-0c4e-4397-9f28-cc6d332a7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = ...\n",
    "mse = ...\n",
    "\n",
    "print('Multiple Linear Regression model coefficients: ', coefficients)\n",
    "print('Mutiple Linear Regression test MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d49317-a1ab-4dc2-a3df-83c056c1c8a9",
   "metadata": {},
   "source": [
    "**Observation**: The model trained on the unscaled data is equivalent to the model trained on the scaled data as can be seen by comparing the two model's test MSE which are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e9e9d4-71f0-4224-a6ac-08bc711d1315",
   "metadata": {},
   "source": [
    "## Task 2.5\n",
    "\n",
    "Next, we implement Lasso regression using `sklearn.linear_model.Lasso` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)). \n",
    "\n",
    "In the following, train a Lasso model on the scaled training data using the regularization parameter $\\lambda = 1$. Note that $\\lambda$ is set by specifying the argument `alpha` in `sklearn.linear_model.Lasso`.\n",
    "\n",
    "Compute the model coefficients (using the `coef_` attribute of the trained model) and the mean squared error on the test data (using the function `sklearn.metrics.mean_squared_error()` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html))).\n",
    "\n",
    "*Note*: The design matrix and the results vector are passed only as arguments to the `fit()` method for `sklearn` models. This is different than for `statsmodels` where we passed the data already at the stage of initializing the model. Additionally, the order in which the design matrix and the results vector are passed to a `sklearn`-model is swapped compared to `statsmodels`!\n",
    "\n",
    "Also note: for linear models in `sklearn` we do not need to manually create an `intercept` column as we can specify if we want an intercept to be included using the `fit_intercept` argument when initializing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f97fb5-5637-4b2b-b2d7-7884dc37e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "coefficients = ...\n",
    "mse = ...\n",
    "\n",
    "print('Model coefficients: ', coefficients)\n",
    "print('Lasso test MSE for alpha = 1: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9808cd-f889-4442-bcc9-f5c24ac65f2e",
   "metadata": {},
   "source": [
    "## Task 2.6\n",
    "\n",
    "For values of $\\lambda$ varying from 0.01 to 2 in steps of 0.01 train Lasso models and compute the model coefficients and the model test MSEs. For each new value of $\\lambda$, append the new model coefficients and test MSEs to lists called `coefficients_Lasso` and `mses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ef5a0-4408-4c23-963f-0673bd5a2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "coefficients_Lasso = []\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10999094-b907-4daf-8ce5-cdff6b982359",
   "metadata": {},
   "source": [
    "Run the two cells below to visualize your coefficients and your MSEs for the different $\\lambda$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df21c5-fa9c-42c1-af6c-ece09c0800e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"x\" + str(v) for v in np.arange(1, 36, 1)]\n",
    "\n",
    "coefs_df = pd.DataFrame(coefficients_Lasso, columns=col_names)\n",
    "\n",
    "coefs_df[\"lambda\"] = alphas\n",
    "coefs_long = pd.melt(coefs_df, id_vars=[\"lambda\"], value_vars=col_names)\n",
    "\n",
    "fig = px.line(coefs_long, x=\"lambda\", y=\"value\", color=\"variable\", log_x=True)\n",
    "fig.update_layout(\n",
    "    showlegend=False, width=1000, height=500, yaxis_title=\"Coefficient\",\n",
    "    xaxis_title=\"Lambda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e795a52-82a8-4fef-adc0-4c59f004b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=alphas, y=mses,\n",
    "        labels={\"x\": \"Lambda\", \"y\": \"MSE\"},\n",
    "        width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91e1cd-b658-4f6c-8c0a-920b1a402af8",
   "metadata": {},
   "source": [
    "## Task 2.7\n",
    "\n",
    "Repeat the steps from Task 2.6, this time using Ridge regression [`sklearn.linear_model.Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge) using a parameter $\\lambda$ which varies from $1$ to $3000$ in steps of $25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be45bc6-f9a3-4781-895f-ebd3f732d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "coefficients_Ridge = []\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980b970-8608-4e3c-8823-b924c7a0985f",
   "metadata": {},
   "source": [
    "Run the two cells below to visualize the coefficients and the test score for the different $\\lambda$ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1520b04-bde7-449d-bdc4-daee03a923d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_Ridge = np.squeeze(coefficients_Ridge)\n",
    "\n",
    "col_names = [\"x\" + str(v) for v in np.arange(1, 36, 1)]\n",
    "\n",
    "coefsR_df = pd.DataFrame(coefficients_Ridge, columns=col_names)\n",
    "coefsR_df[\"lambda\"] = alphasR\n",
    "\n",
    "coefsR_long = pd.melt(coefsR_df, id_vars=[\"lambda\"], value_vars=col_names)\n",
    "\n",
    "fig = px.line(coefsR_long, x=\"lambda\", y=\"value\", color=\"variable\", log_x=True)\n",
    "fig.update_layout(\n",
    "    showlegend=False, width=1000, height=500, \n",
    "    yaxis_title=\"Coefficient\", xaxis_title=\"Lambda\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febfc8d-800a-46cd-b032-67f700734c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=alphasR, y=mses,\n",
    "        labels={\"x\": \"Lambda\", \"y\": \"MSE\"},\n",
    "        width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4fcdd3-d754-4e72-8f74-8e1542be4a9a",
   "metadata": {},
   "source": [
    "## Task 2.8\n",
    "\n",
    "Now we use $10$-fold cross validation to compare the estimated test MSE of OLS multiple linear regression, Lasso regression and Ridge regression.\n",
    "To do so, follow the steps outlined below:\n",
    "- Initialize a `KFold` cross-validator (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)). Make sure to set a random state so that the same folds are used for all models. Also make sure that the data is shuffled.\n",
    "- With this cross-validator, compute the cross validation scores for the regular OLS model. Since in this part we stay completely within `sklearn` and do not use `statsmodels`, there is no need for using `sklearn_sm`. Make sure to specify the appropriate scorer using the `socring` parameter.\n",
    "- For `Lasso` and `Ridge` we need to define pass the model in the form of a pipeline to `cross_validate` to make sure that the standardization is carried out on each of the folds separately. For this, use the function `sklearn.pipeline.make_pipeline` (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) or [here](https://scikit-learn.org/stable/modules/compose.html) for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1695d53-2b31-4b06-aace-f10786f7678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da72d17c-5273-49e7-9404-0754952e293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine OLS cross validation score\n",
    "...\n",
    "cv_err_OLS = -np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad22636-a37d-4807-8700-9c0344945edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Lasso cross validation scores\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "...\n",
    "cv_err_L = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28512af-7918-4fb1-aa65-200e18cd6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Ridge cross validation scores\n",
    "...\n",
    "cv_err_R = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503541a7-abcf-4f0f-bb6b-d04189f4af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross validation score OLS: ', cv_err_OLS)\n",
    "print('Best cross validation score Lasso: ', min(cv_err_L), ' (for parameter alpha = ', \n",
    "      alphas_L[np.argmin(cv_err_L)],')')\n",
    "print('Best cross validation score Ridge: ', min(cv_err_R), ' (for parameter alpha = ', \n",
    "      alphas_R[np.argmin(cv_err_R)],')')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
